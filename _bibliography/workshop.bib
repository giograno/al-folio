@inproceedings{grano2018howhight,
  author    = {Grano, Giovanni and
               Timov, Timofey  and
               Panichella, Sebastiano and
               Gall, Harald},
  title     = {How High Will It Be? Using Machine Learning Models to Predict Branch Coverage in Automated Testing},
  booktitle = {MaLTeSQuE@SANER (to appear)},
  year      = {2018},
  abstract  = {Software testing is a crucial component in modern continuous integration development environment.
Ideally, at every commit, all the system's test cases should be executed and moreover, new test cases should be generated for the new code.
This is especially true in the a Continuous Test Generation (CTG) environment, where the automatic generation of test cases is integrated into the continuous integration pipeline.
Furthermore, developers want to achieve a minimum level of coverage for every build of their systems.
Since both executing all the test cases and generating new ones for all the classes at every commit is not feasible, they have to select which subset of classes has to be tested.
In this context, knowing a priori the branch coverage that can be achieved with test data generation tools might gives some useful indications for answering such a question.
In this paper, we take the first steps towards the definition of machine learning models to predict the branch coverage achieved by test data generation tools.
We conduct a preliminary study considering well known code metrics as a features.
Despite the simplicity of these features, our results show that using machine learning to predict branch coverage in automated testing is a viable and feasible option.},
  pdf = {workshop/maltesque.pdf},
  slides = {slides/maltesque.pdf}
}

@inproceedings{grano2017android,
  author    = {Grano, Giovanni and
               {Di Sorbo}, Andrea and
               Mercaldo, Francesco and
               Visaggio, {Corrado Aaron}  and
               Canfora, Gerardo and
               Panichella, Sebastiano},
  title     = {Android apps and user feedback: a dataset for software evolution and
               quality improvement},
  booktitle = {WAMA@ESEC/SIGSOFT {FSE}},
  abstract  = {Nowadays, Android represents the most popular mobile platform with a market share of around 80%. Previous research showed that data contained in user reviews and code change history of mobile apps represent a rich source of information for reducing software maintenance and development effort, increasing customers' satisfaction. Stemming from this observation, we present in this paper a large dataset of Android applications belonging to 23 different apps categories, which provides an overview of the types of feedback users report on the apps and documents the evolution of the related code metrics. The dataset contains about 395 applications of the F-Droid repository, including around 600 versions, 280,000 user reviews and more than 450,000 user feedback (extracted with specific text mining approaches). Furthermore, for each app version in our dataset, we employed the Paprika tool and developed several Python scripts to detect 8 different code smells and compute 22 code quality indicators. The paper discusses the potential usefulness of the dataset for future research in the field.},
  pdf       = {workshop/wama17.pdf},
  slides    = {slides/wama17.pdf},
  pages     = {8--11},
  publisher = {{ACM}},
  year      = {2017}
}


